{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "\n",
    "path = os.getcwd()\n",
    "os.chdir(f\"{path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data extraction\n",
    "\n",
    "### If 'result' DataFrame needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data structure\n",
    "# .\n",
    "# ├── aps-dataset-metadata-2013\n",
    "# │   └── PR\n",
    "# │   └── PRA\n",
    "# │   └── PRB\n",
    "# │   ...\n",
    "# │   └── RMP\n",
    "# ├── json_to_csv.py\n",
    "# ├── result_PR1.csv\n",
    "# ├── result_PR2.csv\n",
    "# ├── ...\n",
    "# ├── result_RMP1.csv\n",
    "# └── result.csv\n",
    "\n",
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def json_to_df(json_data): # json file to DataFrame in a particular format\n",
    "    \n",
    "    json_cols = json_data.keys()\n",
    "    result = dict()\n",
    "    \n",
    "    if \"id\" in json_cols:\n",
    "        result[\"doi\"] = json_data[\"id\"]\n",
    "    else:\n",
    "        result[\"doi\"] = [\"\"]\n",
    "    \n",
    "    if \"authors\" in json_cols:\n",
    "        numAuthor = len(json_data[\"authors\"])\n",
    "        names = []\n",
    "        surnames = []\n",
    "        \n",
    "        for author in json_data[\"authors\"]:\n",
    "            if \"name\" in author.keys():\n",
    "                names.append(author[\"name\"].lower().replace(\" \", \"\"))\n",
    "            else:\n",
    "                names.append(\"\")\n",
    "            \n",
    "            if \"surname\" in author.keys():\n",
    "                surnames.append(author[\"surname\"].lower())\n",
    "        \n",
    "        result[\"name\"] = names\n",
    "        result[\"order\"] = list(range(1, numAuthor + 1))\n",
    "        result[\"numAuthor\"] = numAuthor\n",
    "        \n",
    "        # alphabetical order\n",
    "        if numAuthor >= 4 and surnames == sorted(surnames):\n",
    "            result[\"is_alpha\"] = True\n",
    "        else:\n",
    "            result[\"is_alpha\"] = False\n",
    "    else:\n",
    "        result[\"name\"] = [\"\"]\n",
    "        result[\"order\"] = [\"\"]\n",
    "        result[\"numAuthor\"] = 0\n",
    "        result[\"is_alpha\"] = False\n",
    "    \n",
    "    if \"date\" in json_cols:\n",
    "        result[\"year\"] = json_data[\"date\"][:4]\n",
    "    else:\n",
    "        result[\"year\"] = [\"\"]\n",
    "    \n",
    "    if \"articleType\" in json_cols:\n",
    "        result[\"articleType\"] = json_data[\"articleType\"]\n",
    "    else:\n",
    "        result[\"articleType\"] = [\"\"]\n",
    "    \n",
    "    if \"journal\" in json_cols:\n",
    "        result[\"journal\"] = json_data[\"journal\"][\"id\"]\n",
    "    else:\n",
    "        result[\"journal\"] = [\"\"]\n",
    "    \n",
    "    for i in range(10):\n",
    "        result[\"pacs\" + str(i) + \"0\"] = 0\n",
    "    \n",
    "    if \"classificationSchemes\" in json_cols and \"pacs\" in json_data[\"classificationSchemes\"].keys():\n",
    "        for pac in json_data[\"classificationSchemes\"][\"pacs\"]:\n",
    "            if pac[\"id\"][0] in list(map(str, range(10))):\n",
    "                result[\"pacs\" + pac[\"id\"][0] + \"0\"] = 1\n",
    "    \n",
    "    return pd.DataFrame(result)\n",
    "\n",
    "def init_df():\n",
    "    \n",
    "    cols = [\"doi\", \"name\", \"order\", \"numAuthor\", \"is_alpha\",\n",
    "            \"year\", \"articleType\", \"journal\"] + [\"pacs\" + str(i) + \"0\" for i in range(10)]\n",
    "    \n",
    "    return pd.DataFrame(columns=cols)\n",
    "\n",
    "# 'aps-dataset-metadata-2013' json files to each dataframe, then to .csv\n",
    "for file_path in glob.glob(\"./aps-dataset-metadata-2013/*\"):\n",
    "    dir_name = file_path.split(\"/\")[-1]\n",
    "    result = init_df() # dataframe default\n",
    "    \n",
    "    for i, file_name in tqdm(enumerate(glob.glob(file_path + \"/**\", recursive=True), 1)):\n",
    "        if file_name.endswith(\".json\"):        \n",
    "            with open(file_name, \"r\") as j:\n",
    "                json_data = json.loads(j.read())\n",
    "                result = result.append(json_to_df(json_data), ignore_index=True)\n",
    "                \n",
    "        if i % 10000 == 0:\n",
    "            file_id = dir_name + str(i // 10000)\n",
    "            result.to_csv(f\"./result_{file_id}.csv\", index=False) # dataframe to csv\n",
    "            result = init_df() # dataframe default\n",
    "            \n",
    "    # dataframe to csv (save)\n",
    "    file_id = dir_name + str(i//10000 + 1)\n",
    "    result.to_csv(f\"./result_{file_id}.csv\", index=False)\n",
    "\n",
    "# csvs to one csv\n",
    "result = init_df()\n",
    "\n",
    "for file_name in tqdm(glob.glob(\"./*\")):\n",
    "    if file_name.endswith(\".csv\"):\n",
    "        result = pd.concat([result, pd.read_csv(file_name)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If 'surnames' DataFrame needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_to_df_sur(json_data):\n",
    "    \n",
    "    json_cols = json_data.keys()\n",
    "    surs = dict()\n",
    "    \n",
    "    if \"authors\" in json_cols:\n",
    "        names = []\n",
    "        surnames = []\n",
    "        \n",
    "        for author in json_data[\"authors\"]:\n",
    "            if \"name\" in author.keys():\n",
    "                names.append(author[\"name\"].lower().replace(\" \", \"\"))\n",
    "            else:\n",
    "                names.append(\"\")\n",
    "            \n",
    "            if \"surname\" in author.keys():\n",
    "                surnames.append(author[\"surname\"].lower())\n",
    "            else:\n",
    "                surnames.append(\"\")\n",
    "        \n",
    "        surs[\"name\"] = names\n",
    "        surs[\"surname\"] = surnames\n",
    "    else:\n",
    "        surs[\"name\"] = [\"\"]\n",
    "        surs[\"surname\"] = [\"\"]\n",
    "\n",
    "    return pd.DataFrame(surs)\n",
    "\n",
    "def init_df_sur():\n",
    "    \n",
    "    cols = [\"name\", \"surname\"]\n",
    "    \n",
    "    return pd.DataFrame(columns=cols)\n",
    "\n",
    "for file_path in glob.glob(\"./aps-dataset-metadata-2013/*\"):\n",
    "    dir_name = file_path.split(\"/\")[-1]\n",
    "    surs = init_df_sur()\n",
    "    \n",
    "    for i, file_name in tqdm(enumerate(glob.glob(file_path + \"/**\", recursive=True), 1)):\n",
    "        if file_name.endswith(\".json\"):        \n",
    "            with open(file_name, \"r\") as j:\n",
    "                json_data = json.loads(j.read())\n",
    "                surs = surs.append(json_to_df_sur(json_data), ignore_index=True)\n",
    "                \n",
    "        if i % 10000 == 0:\n",
    "            file_id = dir_name + str(i // 10000)\n",
    "            surs.to_csv(f\"./surname_{file_id}.csv\", index=False)\n",
    "            surs = init_df_sur()\n",
    "            \n",
    "    file_id = dir_name + str(i//10000 + 1)\n",
    "    surs.to_csv(f\"./surname_{file_id}.csv\", index=False)\n",
    "\n",
    "surs = init_df_sur()\n",
    "\n",
    "for file_name in tqdm(glob.glob(\"./*\")):\n",
    "    if file_name.endswith(\".csv\"):\n",
    "        surs = pd.concat([surs, pd.read_csv(file_name)])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNXs/Kqp8m75qLbgNriQJth",
   "collapsed_sections": [],
   "name": "data_processing_to_samuel.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
