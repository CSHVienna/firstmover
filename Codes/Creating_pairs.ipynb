{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc49116e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb08b3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary data\n",
    "\n",
    "cb = pd.read_csv(\"../citationBara.csv\")\n",
    "primdata = pd.read_csv(\"../primdata.csv\")\n",
    "lastdata = pd.read_csv(\"../lastdata.csv\")\n",
    "pair = pd.read_csv(\"../pairs_edited.csv\")\n",
    "\n",
    "# if pair.csv is too big, try dividing it to chunks\n",
    "\n",
    "# pair = pd.read_csv(\"/Users/robinkong/codes/pairs_edited.csv\", chunksize = 1000000)\n",
    "# pair = list(pair)\n",
    "# pair = pd.concat(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f7db94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### IF PRIMARY ANALYSIS\n",
    "\n",
    "# data = primdata.copy()\n",
    "\n",
    "#### IF LAST AUTHOR ANALYSIS\n",
    "\n",
    "data = lastdata.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a50438b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame: {citing_doi, citing_year, cited_doi}\n",
    "\n",
    "citinfo = data[[\"doi\", \"year\"]].drop_duplicates(subset = 'doi')\n",
    "cols = ['citing_doi', 'citing_year', 'cited_doi']\n",
    "\n",
    "citinfo = citinfo.merge(cb, left_on = 'doi', right_on = 'citing_doi',\n",
    "              how = 'inner').drop(['doi'], axis=1).rename(\n",
    "                  {'year': 'citing_year'}, axis=1).reindex(\n",
    "                      columns=cols).sort_values('cited_doi')\n",
    "\n",
    "# citinfo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fff38d",
   "metadata": {},
   "source": [
    "## m-m pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b414628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choosing pairs where both last authors are men\n",
    "\n",
    "mmpairs = pair[(pair.gender1 == 'male') & (pair.gender2 == 'male')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c7ebab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting for similar m-m pairs\n",
    "\n",
    "sim_mm = mmpairs[['paper1', 'paper2', 'gender1', 'gender2', 'year1', 'year2', 'keyval', 'qval']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770e6f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dummy data (test1, test2) to perform SQL:\n",
    "# Create a DataFrame that treats citation info for male and female papers\n",
    "test1 = sim_mm.merge(citinfo, left_on = 'paper1',\n",
    "                    right_on = 'cited_doi', how = 'left').drop(\n",
    "                        [\"cited_doi\", \"citing_year\"], axis=1).drop_duplicates(\n",
    "                            subset=['paper1', 'citing_doi'])\n",
    "test1['count'] = test1.groupby(['paper1'])['paper1'].transform('count')\n",
    "test1 = test1.drop([\"citing_doi\"], axis=1).rename({'count': 'count1'}, axis=1)\n",
    "\n",
    "test1 = test1.drop_duplicates(subset=['paper1', 'paper2'])[['paper1', 'count1']]\n",
    "sim_mm = sim_mm.merge(test1, on='paper1', how='inner')\n",
    "\n",
    "test2 = sim_mm.merge(citinfo, left_on = 'paper2',\n",
    "                    right_on = 'cited_doi', how = 'left').drop(\n",
    "                        [\"cited_doi\", \"citing_year\"], axis=1).drop_duplicates(\n",
    "                            subset=['paper2', 'citing_doi'])\n",
    "test2['count'] = test2.groupby(['paper2'])['paper2'].transform('count')\n",
    "test2 = test2.drop([\"citing_doi\"], axis=1).rename(\n",
    "    {'count': 'count2'}, axis=1).drop_duplicates(\n",
    "        subset=['paper1', 'paper2'])[['paper2', 'count2']]\n",
    "sim_mm = sim_mm.merge(test2, on='paper2', how='inner')\n",
    "\n",
    "# Delete the dummy data\n",
    "del test1\n",
    "del test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b07de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate year & centrality difference among pairs\n",
    "\n",
    "listd = []\n",
    "listy = []\n",
    "\n",
    "for c in tqdm(range(len(sim_mm))):\n",
    "    listd.append(sim_mm['count1'][c] - sim_mm['count2'][c])\n",
    "    listy.append(sim_mm['year1'][c] - sim_mm['year2'][c])\n",
    "\n",
    "sim_mm['countd'] = listd\n",
    "sim_mm['yeard'] = listy\n",
    "\n",
    "# Keep the minimum q-value per pair\n",
    "sim_mm = sim_mm.sort_values('qval').drop_duplicates(\n",
    "    subset=['paper1', 'paper2'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8f26ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_mm.to_csv(\"../mmpairs_similarity_edited.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4723f3c",
   "metadata": {},
   "source": [
    "## m-w pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9cd347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choosing pairs where one last author is a man and another is a woman\n",
    "\n",
    "mwpairs = pair[(pair.gender1 != pair.gender2)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12315824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting for similar m-m pairs\n",
    "\n",
    "sim_mw = mwpairs[['paper1', 'paper2', 'gender1', 'gender2', 'year1', 'year2', 'keyval', 'qval']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb1b703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dummy data (test1, test2) to perform SQL:\n",
    "# Create a DataFrame that treats citation info for male and female papers\n",
    "test1 = sim_mw.merge(citinfo, left_on = 'paper1',\n",
    "                    right_on = 'cited_doi', how = 'left').drop(\n",
    "                        [\"cited_doi\", \"citing_year\"], axis=1).drop_duplicates(\n",
    "                            subset=['paper1', 'citing_doi'])\n",
    "test1['count'] = test1.groupby(['paper1'])['paper1'].transform('count')\n",
    "test1 = test1.drop([\"citing_doi\"], axis=1).rename({'count': 'count1'}, axis=1)\n",
    "\n",
    "test1 = test1.drop_duplicates(subset=['paper1', 'paper2'])[['paper1', 'count1']]\n",
    "sim_mw = sim_mw.merge(test1, on='paper1', how='inner')\n",
    "\n",
    "test2 = sim_mw.merge(citinfo, left_on = 'paper2',\n",
    "                    right_on = 'cited_doi', how = 'left').drop(\n",
    "                        [\"cited_doi\", \"citing_year\"], axis=1).drop_duplicates(\n",
    "                            subset=['paper2', 'citing_doi'])\n",
    "test2['count'] = test2.groupby(['paper2'])['paper2'].transform('count')\n",
    "test2 = test2.drop([\"citing_doi\"], axis=1).rename(\n",
    "    {'count': 'count2'}, axis=1).drop_duplicates(\n",
    "        subset=['paper1', 'paper2'])[['paper2', 'count2']]\n",
    "sim_mw = sim_mw.merge(test2, on='paper2', how='inner')\n",
    "\n",
    "# Delete the dummy data\n",
    "del test1\n",
    "del test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5a6dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate year & centrality difference among pairs\n",
    "\n",
    "listd = []\n",
    "listy = []\n",
    "\n",
    "for c in tqdm(range(len(sim_mw))):\n",
    "    if sim_mw['gender1'][c] == 'male':\n",
    "        listd.append(sim_mw['count1'][c] - sim_mw['count2'][c])\n",
    "        listy.append(sim_mw['year1'][c] - sim_mw['year2'][c])\n",
    "    else:\n",
    "        listd.append(sim_mw['count2'][c] - sim_mw['count1'][c])\n",
    "        listy.append(sim_mw['year2'][c] - sim_mw['year1'][c])\n",
    "\n",
    "sim_mw['countd'] = listd\n",
    "sim_mw['yeard'] = listy\n",
    "\n",
    "# Keep the minimum q-value per pair\n",
    "sim_mw = sim_mw.sort_values('qval').drop_duplicates(\n",
    "    subset=['paper1', 'paper2'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa81abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_mw.to_csv(\"../mwpairs_similarity_edited.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa922061",
   "metadata": {},
   "source": [
    "## w-w pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b5812d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choosing pairs where both last authors are women\n",
    "\n",
    "wwpairs = pair[(pair.gender1 == 'female') & (pair.gender2 == 'female')].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cbd2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting for similar m-m pairs\n",
    "\n",
    "sim_ww = wwpairs[['paper1', 'paper2', 'gender1', 'gender2', 'year1', 'year2', 'keyval', 'qval']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d779a353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dummy data (test1, test2) to perform SQL:\n",
    "# Create a DataFrame that treats citation info for male and female papers\n",
    "test1 = sim_ww.merge(citinfo, left_on = 'paper1',\n",
    "                    right_on = 'cited_doi', how = 'left').drop(\n",
    "                        [\"cited_doi\", \"citing_year\"], axis=1).drop_duplicates(\n",
    "                            subset=['paper1', 'citing_doi'])\n",
    "test1['count'] = test1.groupby(['paper1'])['paper1'].transform('count')\n",
    "test1 = test1.drop([\"citing_doi\"], axis=1).rename({'count': 'count1'}, axis=1)\n",
    "\n",
    "test1 = test1.drop_duplicates(subset=['paper1', 'paper2'])[['paper1', 'count1']]\n",
    "sim_ww = sim_ww.merge(test1, on='paper1', how='inner')\n",
    "\n",
    "test2 = sim_ww.merge(citinfo, left_on = 'paper2',\n",
    "                    right_on = 'cited_doi', how = 'left').drop(\n",
    "                        [\"cited_doi\", \"citing_year\"], axis=1).drop_duplicates(\n",
    "                            subset=['paper2', 'citing_doi'])\n",
    "test2['count'] = test2.groupby(['paper2'])['paper2'].transform('count')\n",
    "test2 = test2.drop([\"citing_doi\"], axis=1).rename(\n",
    "    {'count': 'count2'}, axis=1).drop_duplicates(\n",
    "        subset=['paper1', 'paper2'])[['paper2', 'count2']]\n",
    "sim_ww = sim_ww.merge(test2, on='paper2', how='inner')\n",
    "\n",
    "# Delete the dummy data\n",
    "del test1\n",
    "del test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c3ab8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate year & centrality difference among pairs\n",
    "\n",
    "listd = []\n",
    "listy = []\n",
    "\n",
    "for c in tqdm(range(len(sim_ww))):\n",
    "    listd.append(sim_ww['count1'][c] - sim_ww['count2'][c])\n",
    "    listy.append(sim_ww['year1'][c] - sim_ww['year2'][c])\n",
    "\n",
    "sim_ww['countd'] = listd\n",
    "sim_ww['yeard'] = listy\n",
    "\n",
    "# Keep the minimum q-value per pair\n",
    "sim_ww = sim_ww.sort_values('qval').drop_duplicates(\n",
    "    subset=['paper1', 'paper2'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64723652",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_ww.to_csv(\"../wwpairs_similarity_edited.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
